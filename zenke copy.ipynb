{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "\n",
    "from heidel_utils import get_shd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inputs  = 700\n",
    "nb_hidden  = 200\n",
    "nb_outputs = 20\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps = 100\n",
    "max_time = 1.4\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available at: /Users/kerstjens/data/hdspikes/shd_train.h5\n",
      "Available at: /Users/kerstjens/data/hdspikes/shd_test.h5\n"
     ]
    }
   ],
   "source": [
    "# Here we load the Dataset\n",
    "cache_dir = os.path.expanduser(\"~/data\")\n",
    "cache_subdir = \"hdspikes\"\n",
    "get_shd_dataset(cache_dir, cache_subdir)\n",
    "\n",
    "train_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_train.h5'), 'r')\n",
    "test_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_test.h5'), 'r')\n",
    "\n",
    "x_train = train_file['spikes']\n",
    "y_train = train_file['labels']\n",
    "x_test = test_file['spikes']\n",
    "y_test = test_file['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_data_generator_from_hdf5_spikes(X, y, batch_size, nb_steps, nb_units, max_time, shuffle=True):\n",
    "    \"\"\" This generator takes a spike dataset and generates spiking network input as sparse tensors. \n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y,dtype=np.int)\n",
    "    number_of_batches = len(labels_)//batch_size\n",
    "    sample_index = np.arange(len(labels_))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    firing_times = X['times']\n",
    "    units_fired = X['units']\n",
    "    \n",
    "    time_bins = np.linspace(0, max_time, num=nb_steps)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        coo = [ [] for i in range(3) ]\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            times = np.digitize(firing_times[idx], time_bins)\n",
    "            units = units_fired[idx]\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            \n",
    "            coo[0].extend(batch)\n",
    "            coo[1].extend(times)\n",
    "            coo[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "    \n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size,nb_steps,nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 0.2\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "v1 = torch.empty((nb_hidden, nb_hidden), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(v1, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "v2 = torch.empty((nb_hidden, nb_hidden), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(v2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "w3 = torch.empty((nb_hidden, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w3, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "v3 = torch.empty((nb_hidden, nb_hidden), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(v3, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "w4 = torch.empty((nb_hidden, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w4, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "v4 = torch.empty((nb_hidden, nb_hidden), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(v4, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "w5 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w5, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(3,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = 1.0*mem\n",
    "        dat[spk>0.0] = spike_height\n",
    "        dat = dat.detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def live_plot(loss):\n",
    "    if len(loss) == 1:\n",
    "        return\n",
    "    clear_output(wait=True)\n",
    "    ax = plt.figure(figsize=(3,2), dpi=150).gca()\n",
    "    ax.plot(range(1, len(loss) + 1), loss)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.xaxis.get_major_locator().set_params(integer=True)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    out = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    h1_from_input = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    for t in range(nb_steps):\n",
    "        h1 = h1_from_input[:,t] + torch.einsum(\"ab,bc->ac\", (out, v1))\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1\n",
    "        new_mem =(beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    syn_2 = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem_2 = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec_2 = []\n",
    "    spk_rec_2 = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    out_2 = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    h2_from_hidden = torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    for t in range(nb_steps):\n",
    "        h2 = h2_from_hidden[:,t] + torch.einsum(\"ab,bc->ac\", (out_2, v2))\n",
    "        mthr_2 = mem_2-1.0\n",
    "        out_2 = spike_fn(mthr_2)\n",
    "        rst_2 = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn_2 = alpha*syn_2 +h2\n",
    "        new_mem_2 =(beta*mem_2 +syn_2)*(1.0-rst_2)\n",
    "\n",
    "        mem_rec_2.append(mem_2)\n",
    "        spk_rec_2.append(out_2)\n",
    "        \n",
    "        mem_2 = new_mem_2\n",
    "        syn_2 = new_syn_2\n",
    "\n",
    "    mem_rec_2 = torch.stack(mem_rec_2,dim=1)\n",
    "    spk_rec_2 = torch.stack(spk_rec_2,dim=1)\n",
    "\n",
    "    syn_3 = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem_3 = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec_3 = []\n",
    "    spk_rec_3 = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    out_3 = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    h3_from_hidden = torch.einsum(\"abc,cd->abd\", (spk_rec, w3))\n",
    "    for t in range(nb_steps):\n",
    "        h3 = h3_from_hidden[:,t] + torch.einsum(\"ab,bc->ac\", (out_3, v3))\n",
    "        mthr_3 = mem_3-1.0\n",
    "        out_3 = spike_fn(mthr_3)\n",
    "        rst_3 = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn_3 = alpha*syn_3 +h3\n",
    "        new_mem_3 =(beta*mem_3 +syn_3)*(1.0-rst_3)\n",
    "\n",
    "        mem_rec_3.append(mem_3)\n",
    "        spk_rec_3.append(out_3)\n",
    "        \n",
    "        mem_3 = new_mem_3\n",
    "        syn_3 = new_syn_3\n",
    "\n",
    "    mem_rec_3 = torch.stack(mem_rec_3,dim=1)\n",
    "    spk_rec_3 = torch.stack(spk_rec_3,dim=1)\n",
    "\n",
    "    syn_4 = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem_4 = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec_4 = []\n",
    "    spk_rec_4 = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    out_4 = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    h4_from_hidden = torch.einsum(\"abc,cd->abd\", (spk_rec, w4))\n",
    "    for t in range(nb_steps):\n",
    "        h4 = h4_from_hidden[:,t] + torch.einsum(\"ab,bc->ac\", (out_4, v4))\n",
    "        mthr_4 = mem_4-1.0\n",
    "        out_4 = spike_fn(mthr_4)\n",
    "        rst_4 = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn_4 = alpha*syn_4 +h4\n",
    "        new_mem_4 =(beta*mem_4 +syn_4)*(1.0-rst_4)\n",
    "\n",
    "        mem_rec_4.append(mem_4)\n",
    "        spk_rec_4.append(out_4)\n",
    "        \n",
    "        mem_4 = new_mem_4\n",
    "        syn_4 = new_syn_4\n",
    "\n",
    "    mem_rec_4 = torch.stack(mem_rec_4,dim=1)\n",
    "    spk_rec_4 = torch.stack(spk_rec_4,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h5= torch.einsum(\"abc,cd->abd\", (spk_rec, w5))\n",
    "    flt_5 = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_5 = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec_5 = [out_5]\n",
    "    for t in range(nb_steps):\n",
    "        new_flt_5 = alpha*flt_5 +h5[:,t]\n",
    "        new_out_5 = beta*out_5 +flt_5\n",
    "\n",
    "        flt_5= new_flt_5\n",
    "        out_5 = new_out_5\n",
    "\n",
    "        out_rec_5.append(out_5)\n",
    "\n",
    "    out_rec_5 = torch.stack(out_rec_5,dim=1)\n",
    "    other_recs_5 = [mem_rec_4, spk_rec_4]\n",
    "    return out_rec_5, other_recs_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_data, y_data, lr=1e-3, nb_epochs=10):\n",
    "    \n",
    "    params = [w1,w2,w3,w4,w5,v1,v2,v3,v4]\n",
    "    optimizer = torch.optim.Adamax(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        for x_local, y_local in sparse_data_generator_from_hdf5_spikes(x_data, y_data, batch_size, nb_steps, nb_inputs, max_time):\n",
    "            output,recs = run_snn(x_local.to_dense())\n",
    "            _,spks=recs\n",
    "            m,_=torch.max(output,1)\n",
    "            log_p_y = log_softmax_fn(m)\n",
    "            \n",
    "            # Here we set up our regularizer loss\n",
    "            # The strength paramters here are merely a guess and there should be ample room for improvement by\n",
    "            # tuning these paramters.\n",
    "            reg_loss = 2e-6*torch.sum(spks) # L1 loss on total number of spikes\n",
    "            reg_loss += 2e-6*torch.mean(torch.sum(torch.sum(spks,dim=0),dim=0)**2) # L2 loss on spikes per neuron\n",
    "            \n",
    "            # Here we combine supervised loss and the regularizer\n",
    "            loss_val = loss_fn(log_p_y, y_local) + reg_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        loss_hist.append(mean_loss)\n",
    "        live_plot(loss_hist)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        \n",
    "    return loss_hist\n",
    "        \n",
    "        \n",
    "def compute_classification_accuracy(x_data, y_data):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    for x_local, y_local in sparse_data_generator_from_hdf5_spikes(x_data, y_data, batch_size, nb_steps, nb_inputs, max_time, shuffle=False):\n",
    "        output,_ = run_snn(x_local.to_dense())\n",
    "        m,_= torch.max(output,1) # max over time\n",
    "        _,am=torch.max(m,1)      # argmax over output units\n",
    "        tmp = np.mean((y_local==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss=1.51533\n"
     ]
    }
   ],
   "source": [
    "loss_hist = train(x_train, y_train, lr=2e-4, nb_epochs=nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167615/3193409431.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  labels_ = np.array(y,dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.612\n",
      "Test accuracy: 0.556\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(x_train,y_train)))\n",
    "print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6200234780f1abd365c930dddb95b38298813a9988d77a8785e770f4fc612d5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
