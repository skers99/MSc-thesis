{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'heidel_utils' from '/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel_utils.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "import heidel_utils\n",
    "from importlib import reload # reload \n",
    "reload(heidel_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 700\n",
    "nb_hidden  = 200\n",
    "nb_outputs = 20\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps = 100\n",
    "max_time = 1.4\n",
    "\n",
    "batch_size = 256\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'device: {device}')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available at: /Users/svenkerstjens/data/hdspikes/shd_train.h5\n",
      "Available at: /Users/svenkerstjens/data/hdspikes/shd_test.h5\n"
     ]
    }
   ],
   "source": [
    "# Here we load the Dataset\n",
    "cache_dir = os.path.expanduser(\"~/data\")\n",
    "cache_subdir = \"hdspikes\"\n",
    "heidel_utils.get_shd_dataset(cache_dir, cache_subdir)\n",
    "\n",
    "train_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_train.h5'), 'r')\n",
    "test_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_test.h5'), 'r')\n",
    "\n",
    "x_train = train_file['spikes']\n",
    "y_train = train_file['labels']\n",
    "x_test = test_file['spikes']\n",
    "y_test = test_file['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_data_generator_from_hdf5_spikes(X, y, batch_size, nb_steps, nb_units, max_time, shuffle=True):\n",
    "    \"\"\" This generator takes a spike dataset and generates spiking network input as sparse tensors.\n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y,dtype=np.int)\n",
    "    number_of_batches = len(labels_)//batch_size\n",
    "    sample_index = np.arange(len(labels_))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    firing_times = X['times']\n",
    "    units_fired = X['units']\n",
    "\n",
    "    time_bins = np.linspace(0, max_time, num=nb_steps)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        coo = [ [] for i in range(3) ]\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            times = np.digitize(firing_times[idx], time_bins)\n",
    "            units = units_fired[idx]\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "\n",
    "            coo[0].extend(batch)\n",
    "            coo[1].extend(times)\n",
    "            coo[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "\n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size,nb_steps,nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OneHiddenModel' from 'LIFlayer' (/Users/svenkerstjens/msc-thesis/MSc-thesis/LIFlayer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000004?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mLIFlayer\u001b[39;00m \u001b[39mimport\u001b[39;00m OneHiddenModel\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000004?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m OneHiddenModel(in_channels\u001b[39m=\u001b[39mnb_inputs,hidden_channels\u001b[39m=\u001b[39mnb_hidden,out_channels\u001b[39m=\u001b[39mnb_outputs,batch_size\u001b[39m=\u001b[39mbatch_size,W\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000004?line=4'>5</a>\u001b[0m ce_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OneHiddenModel' from 'LIFlayer' (/Users/svenkerstjens/msc-thesis/MSc-thesis/LIFlayer.py)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from LIFlayer import OneHiddenModel\n",
    "model = OneHiddenModel(in_channels=nb_inputs,hidden_channels=nb_hidden,out_channels=nb_outputs,batch_size=batch_size,W=None)\n",
    "\n",
    "ce_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "params = model.parameters()\n",
    "opt = torch.optim.Adam(params, lr=1e-4, betas=[0., .95]) #lr is the learning rate\n",
    "decay = .9\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    sum_acc=0\n",
    "    #batches\n",
    "    for x,y in sparse_data_generator_from_hdf5_spikes(x_train, y_train, batch_size, nb_steps, nb_units=nb_inputs, max_time=max_time, shuffle=True):\n",
    "        tik = time.time()\n",
    "        model.init_states()\n",
    "\n",
    "        Sprobe = torch.zeros((batch_size,model.out_channels))\n",
    "\n",
    "        #timesteps\n",
    "        for n in range(nb_steps):\n",
    "            out_state = model(x.to_dense()[:,n])\n",
    "\n",
    "            #add decay for leakiness\n",
    "            #collect spikes over time\n",
    "            Sprobe = decay * Sprobe + out_state.S\n",
    "\n",
    "\n",
    "        prediction = Sprobe\n",
    "        #if i==0:\n",
    "        #    print(prediction)\n",
    "\n",
    "        #accuracy = val_accuracy(prediction,y_train[train_batch_ids[i]])\n",
    "\n",
    "        #class labels only\n",
    "        loss = ce_loss(prediction,y)\n",
    "\n",
    "        print(f'batchloss:  {loss}')\n",
    "\n",
    "        #tonic & torch neuromorphic\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        #model.init_mod_weights(W2)\n",
    "        #sum_acc = sum_acc + accuracy\n",
    "        #sum_loss = sum_loss + loss\n",
    "        count = 0\n",
    "        avg_loss = ((avg_loss * count) + loss)/(count+1)\n",
    "        count += 1\n",
    "    #avg_train_acc = sum_acc/(len(train_batch_ids))\n",
    "    #avg_loss = sum_loss/(len(train_batch_ids))\n",
    "    #if i == 3:/'\n",
    "    #loss_hist = loss_hist + [float(avg_loss)]\n",
    "    #acc_hist = acc_hist + [float(avg_train_acc)]\n",
    "        tok = time.time()\n",
    "        print(f'time for batch: {tok-tik}')\n",
    "    toc = time.time()\n",
    "    print(f'time for epoch {epoch}: {toc-tic}')\n",
    "    if epoch%1==0:\n",
    "        print(f'epoch {epoch}: \\n loss: {avg_loss}')\n",
    "        #print(f'train_acc: {avg_train_acc}')\n",
    "    #val_acc,_,_ = validation_acc(X_test,y_test,model,test_batch_ids)\n",
    "    #val_acc_hist = val_acc_hist + [val_acc]\n",
    "    #print(f'val_acc: {val_acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6200234780f1abd365c930dddb95b38298813a9988d77a8785e770f4fc612d5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
