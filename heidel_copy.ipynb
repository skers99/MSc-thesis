{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'heidel_utils' from '/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel_utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "import heidel_utils\n",
    "from importlib import reload # reload \n",
    "reload(heidel_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[97, 14, 12,  ..., 22, 78,  3],\n",
       "        [36, 82, 60,  ..., 35, 50, 80],\n",
       "        [57, 99, 21,  ..., 26, 68, 51],\n",
       "        ...,\n",
       "        [89, 24,  5,  ..., 59, 90, 96],\n",
       "        [98, 64,  8,  ..., 78, 65, 88],\n",
       "        [14, 18, 23,  ..., 12, 72, 59]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "NeuronState = namedtuple('NeuronState', ['U', 'I', 'S'])\n",
    "\n",
    "class LIFDensePopulation(nn.Module):\n",
    "    # NeuronState = namedtuple('NeuronState', ['U', 'I', 'S'])\n",
    "    def __init__(self, in_channels, out_channels, bias=True, alpha = .9, beta=.85, batch_size=10,W=None):\n",
    "        super(LIFDensePopulation, self).__init__()\n",
    "        self.fc_layer = nn.Linear(in_channels, out_channels)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.state = NeuronState(U=torch.zeros(batch_size, out_channels).to(device),\n",
    "                                 I=torch.zeros(batch_size, out_channels).to(device),\n",
    "                                 S=torch.zeros(batch_size, out_channels).to(device))\n",
    "        self.NeuronState = self.state\n",
    "        self.fc_layer.weight.data.uniform_(-.3, .3)\n",
    "        self.fc_layer.bias.data.uniform_(-.01, .01)\n",
    "\n",
    "\n",
    "    def forward(self, Sin_t):\n",
    "        state = self.state\n",
    "        U = self.alpha*state.U + state.I - state.S #mem\n",
    "        I = self.beta*state.I + self.fc_layer(Sin_t) #syn\n",
    "        # update the neuronal state\n",
    "        S = smooth_step(U)\n",
    "        self.state = NeuronState(U=U, I=I, S=S)\n",
    "        self.NeuronState = self.state\n",
    "        #state = NeuronState(U=U, I=I, S=S)\n",
    "        return self.state\n",
    "\n",
    "    def init_state(self):\n",
    "\n",
    "        out_channels = self.out_channels\n",
    "        self.state = NeuronState(U=torch.zeros(self.batch_size, out_channels,device=device),\n",
    "                                 I=torch.zeros(self.batch_size, out_channels,device=device),\n",
    "                                 S=torch.zeros(self.batch_size, out_channels,device=device))\n",
    "        self.NeuronState = self.state\n",
    "\n",
    "    def init_mod_weights(self,W):\n",
    "        self.fc_layer.weight = torch.nn.Parameter(self.fc_layer.weight.data * torch.Tensor(W))\n",
    "\n",
    "class LifRecPopulation(nn.Module):\n",
    "    # NeuronState = namedtuple('NeuronState', ['U', 'I', 'S'])\n",
    "    def __init__(self, in_channels, out_channels, bias=True, alpha = .9, beta=.85, batch_size=10,W=None):\n",
    "        super(LifRecPopulation, self).__init__()\n",
    "        self.fc_layer = nn.Linear(in_channels, out_channels)\n",
    "        self.rec_layer = nn.Linear(out_channels, out_channels)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.state = NeuronState(U=torch.zeros(batch_size, out_channels).to(device),\n",
    "                                 I=torch.zeros(batch_size, out_channels).to(device),\n",
    "                                 S=torch.zeros(batch_size, out_channels).to(device))\n",
    "        self.NeuronState = self.state\n",
    "        self.fc_layer.weight.data.uniform_(-.3, .3)\n",
    "        self.fc_layer.bias.data.uniform_(-.01, .01)\n",
    "        self.rec_layer.weight.data.uniform_(-.3, .3)\n",
    "        self.rec_layer.bias.data.uniform_(-.01, .01)\n",
    "\n",
    "\n",
    "    def forward(self, Sin_t):\n",
    "        state = self.state\n",
    "        U = self.alpha*state.U + state.I - state.S #mem\n",
    "        I = self.beta*state.I + self.fc_layer(Sin_t) + self.rec_layer(state.S) #syn\n",
    "        # update the neuronal state\n",
    "        S = smooth_step(U)\n",
    "        self.state = NeuronState(U=U, I=I, S=S)\n",
    "        self.NeuronState = self.state\n",
    "        #state = NeuronState(U=U, I=I, S=S)\n",
    "        return self.state\n",
    "\n",
    "    def init_state(self):\n",
    "\n",
    "        out_channels = self.out_channels\n",
    "        self.state = NeuronState(U=torch.zeros(self.batch_size, out_channels,device=device),\n",
    "                                 I=torch.zeros(self.batch_size, out_channels,device=device),\n",
    "                                 S=torch.zeros(self.batch_size, out_channels,device=device))\n",
    "        self.NeuronState = self.state\n",
    "\n",
    "    def init_mod_weights(self,W):\n",
    "        self.fc_layer.weight = torch.nn.Parameter(self.fc_layer.weight.data * torch.Tensor(W))\n",
    "\n",
    "\n",
    "class SmoothStep(torch.autograd.Function):\n",
    "    '''\n",
    "    Modified from: https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html\n",
    "    '''\n",
    "\n",
    "    scale = 100.0\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(aux, x):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which\n",
    "        we need to later backpropagate our error signals. To achieve this we use the\n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        aux.save_for_backward(x)\n",
    "        out = torch.zeros_like(x)\n",
    "\n",
    "        out[x > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    def backward(aux, grad_output):\n",
    "        \n",
    "        #grad_input = grad_output.clone()\n",
    "        input, = aux.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SmoothStep.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "\n",
    "\n",
    "smooth_step = SmoothStep().apply\n",
    "\n",
    "class OneHiddenModel(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,hidden_channels,out_channels,batch_size,alpha=.9,beta=.85,device='cpu',W=None):\n",
    "        super(OneHiddenModel, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.W = W\n",
    "        self.layer1 = LIFDensePopulation(in_channels=self.in_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size,W=W).to(device)\n",
    "        self.layer2 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.out_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "\n",
    "    def forward(self,Sin):\n",
    "        hidden = self.layer1(Sin)\n",
    "        out = self.layer2(hidden.S)\n",
    "        return out\n",
    "\n",
    "    def init_states(self):\n",
    "        self.layer1.init_state()\n",
    "        self.layer2.init_state()\n",
    "\n",
    "    def init_mod_weights(self,W):\n",
    "        self.layer1.fc_layer.weight = torch.nn.Parameter(self.layer1.fc_layer.weight.data * torch.Tensor(W))\n",
    "\n",
    "class OneRecHiddenModel(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,hidden_channels,out_channels,batch_size,alpha=.9,beta=.85,device='cpu',W=None):\n",
    "        super(OneRecHiddenModel, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.W = W\n",
    "        self.layer1 = LifRecPopulation(in_channels=self.in_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size,W=W).to(device)\n",
    "        self.layer2 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.out_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "\n",
    "    def forward(self,Sin):\n",
    "        hidden = self.layer1(Sin)\n",
    "        out = self.layer2(hidden.S)\n",
    "        return out\n",
    "\n",
    "    def init_states(self):\n",
    "        self.layer1.init_state()\n",
    "        self.layer2.init_state()\n",
    "\n",
    "    def init_mod_weights(self,W):\n",
    "        self.layer1.fc_layer.weight = torch.nn.Parameter(self.layer1.fc_layer.weight.data * torch.Tensor(W))\n",
    "\n",
    "class ThreeHiddenModel(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,hidden_channels,out_channels,batch_size,alpha=.9,beta=.85,device='cpu',W=None):\n",
    "        super(ThreeHiddenModel, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.W = W\n",
    "        self.layer1 = LIFDensePopulation(in_channels=self.in_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size,W=W).to(device)\n",
    "        self.layer2 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        self.layer3 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        self.layer4 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        self.layer5 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.out_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "\n",
    "    def forward(self,Sin):\n",
    "        hidden1 = self.layer1(Sin)\n",
    "        hidden2 = self.layer2(hidden1.S)\n",
    "        hidden3 = self.layer3(hidden2.S)\n",
    "        hidden4 = self.layer4(hidden3.S)\n",
    "        out = self.layer5(hidden4.S)\n",
    "        return out\n",
    "\n",
    "    def init_states(self):\n",
    "        self.layer1.init_state()\n",
    "        self.layer2.init_state()\n",
    "        self.layer3.init_state()\n",
    "        self.layer4.init_state()\n",
    "        self.layer5.init_state()\n",
    "\n",
    "    def init_mod_weights(self,W):\n",
    "        self.layer1.fc_layer.weight = torch.nn.Parameter(self.layer1.fc_layer.weight.data * torch.Tensor(W))\n",
    "        self.layer2.fc_layer.weight = torch.nn.Parameter(self.layer2.fc_layer.weight.data * torch.Tensor(W))\n",
    "        self.layer3.fc_layer.weight = torch.nn.Parameter(self.layer3.fc_layer.weight.data * torch.Tensor(W))\n",
    "        self.layer4.fc_layer.weight = torch.nn.Parameter(self.layer4.fc_layer.weight.data * torch.Tensor(W))\n",
    "\n",
    "\n",
    "class FiveHiddenModel(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,hidden_channels,out_channels,batch_size,alpha=.9,beta=.85,device='cpu',W=None):\n",
    "        super(FiveHiddenModel, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.W = W\n",
    "        self.layer1 = LIFDensePopulation(in_channels=self.in_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size,W=W).to(device)\n",
    "        self.layer2 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        self.layer3 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        self.layer4 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        self.layer5 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.hidden_channels,\n",
    "                                        alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        self.layer6 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.hidden_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        self.layer7 = LIFDensePopulation(in_channels=self.hidden_channels,out_channels=self.out_channels,\n",
    "                                         alpha=self.alpha,beta=self.beta,batch_size=self.batch_size).to(device)\n",
    "        #maybe try last layer non- spiking\n",
    "\n",
    "    def forward(self,Sin):\n",
    "        hidden1 = self.layer1(Sin)\n",
    "        hidden2 = self.layer2(hidden1.S)\n",
    "        hidden3 = self.layer3(hidden2.S)\n",
    "        hidden4 = self.layer4(hidden3.S)\n",
    "        hidden5 = self.layer5(hidden4.S)\n",
    "        hidden6 = self.layer6(hidden5.S)\n",
    "        out = self.layer7(hidden6.S)\n",
    "        return out\n",
    "\n",
    "    def init_states(self):\n",
    "        self.layer1.init_state()\n",
    "        self.layer2.init_state()\n",
    "        self.layer3.init_state()\n",
    "        self.layer4.init_state()\n",
    "        self.layer5.init_state()\n",
    "        self.layer6.init_state()\n",
    "        self.layer7.init_state()\n",
    "\n",
    "    def init_mod_weights(self,W):\n",
    "        self.layer1.fc_layer.weight = torch.nn.Parameter(self.layer1.fc_layer.weight.data * torch.Tensor(W))\n",
    "        self.layer2.fc_layer.weight = torch.nn.Parameter(self.layer2.fc_layer.weight.data * torch.Tensor(W))\n",
    "        self.layer3.fc_layer.weight = torch.nn.Parameter(self.layer3.fc_layer.weight.data * torch.Tensor(W))\n",
    "        self.layer4.fc_layer.weight = torch.nn.Parameter(self.layer4.fc_layer.weight.data * torch.Tensor(W))\n",
    "        self.layer5.fc_layer.weight = torch.nn.Parameter(self.layer5.fc_layer.weight.data * torch.Tensor(W))\n",
    "        self.layer6.fc_layer.weight = torch.nn.Parameter(self.layer6.fc_layer.weight.data * torch.Tensor(W))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 700\n",
    "nb_hidden  = 200\n",
    "nb_outputs = 20\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps = 100\n",
    "max_time = 1.4\n",
    "\n",
    "batch_size = 256\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'device: {device}')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available at: /Users/svenkerstjens/data/hdspikes/shd_train.h5\n",
      "Available at: /Users/svenkerstjens/data/hdspikes/shd_test.h5\n"
     ]
    }
   ],
   "source": [
    "# Here we load the Dataset\n",
    "cache_dir = os.path.expanduser(\"~/data\")\n",
    "cache_subdir = \"hdspikes\"\n",
    "heidel_utils.get_shd_dataset(cache_dir, cache_subdir)\n",
    "\n",
    "train_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_train.h5'), 'r')\n",
    "test_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_test.h5'), 'r')\n",
    "\n",
    "x_train = train_file['spikes']\n",
    "y_train = train_file['labels']\n",
    "x_test = test_file['spikes']\n",
    "y_test = test_file['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "legacy constructor expects device type: cpu but device type: cuda was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/kerstjens/msc_thesis/msc_thesis/heidel.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpu4/Users/kerstjens/msc_thesis/msc_thesis/heidel.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mFloatTensor(\u001b[39m3\u001b[39;49m,device\u001b[39m=\u001b[39;49mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: legacy constructor expects device type: cpu but device type: cuda was passed"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_data_generator_from_hdf5_spikes(X, y, batch_size, nb_steps, nb_units, max_time, shuffle=True):\n",
    "    \"\"\" This generator takes a spike dataset and generates spiking network input as sparse tensors.\n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y,dtype=np.int)\n",
    "    number_of_batches = len(labels_)//batch_size\n",
    "    sample_index = np.arange(len(labels_))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    firing_times = X['times']\n",
    "    units_fired = X['units']\n",
    "\n",
    "    time_bins = np.linspace(0, max_time, num=nb_steps)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        coo = [ [] for i in range(3) ]\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            times = np.digitize(firing_times[idx], time_bins)\n",
    "            units = units_fired[idx]\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "\n",
    "            coo[0].extend(batch)\n",
    "            coo[1].extend(times)\n",
    "            coo[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "\n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size,nb_steps,nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/8f66tcbn07n474q76db1wfyc0000gn/T/ipykernel_29734/915459707.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  labels_ = np.array(y,dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchloss:  7.76291561126709\n",
      "batchloss:  8.135481834411621\n",
      "batchloss:  8.35159683227539\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000008?line=26'>27</a>\u001b[0m \u001b[39m#timesteps\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000008?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nb_steps):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000008?line=28'>29</a>\u001b[0m     out_state \u001b[39m=\u001b[39m model(x\u001b[39m.\u001b[39;49mto_dense()[:,n])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000008?line=30'>31</a>\u001b[0m     \u001b[39m#add decay for leakiness\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000008?line=31'>32</a>\u001b[0m     \u001b[39m#collect spikes over time\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svenkerstjens/msc-thesis/MSc-thesis/heidel.ipynb#ch0000008?line=32'>33</a>\u001b[0m     Sprobe \u001b[39m=\u001b[39m decay \u001b[39m*\u001b[39m Sprobe \u001b[39m+\u001b[39m out_state\u001b[39m.\u001b[39mS\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = OneRecHiddenModel(in_channels=nb_inputs,hidden_channels=nb_hidden,out_channels=nb_outputs,batch_size=batch_size,W=None).to(device)\n",
    "\n",
    "ce_loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "params = model.parameters()\n",
    "opt = torch.optim.Adam(params, lr=2e-4, betas=[0., .95]) #lr is the learning rate\n",
    "#decay = .9\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    sum_acc=0\n",
    "    count = 0\n",
    "\n",
    "    #batches\n",
    "    for x,y in sparse_data_generator_from_hdf5_spikes(x_train, y_train, batch_size, nb_steps, nb_units=nb_inputs, max_time=max_time, shuffle=True):\n",
    "        \n",
    "        model.init_states()\n",
    "\n",
    "        #Sprobe = torch.zeros((batch_size,model.out_channels),device=device)\n",
    "        out = torch.zeros((batch_size,model.out_channels))\n",
    "        out_rec = [out]\n",
    "        #timesteps\n",
    "        for n in range(nb_steps):\n",
    "            out_state = model(x.to_dense()[:,n])\n",
    "            out_rec.append(out_state.U)\n",
    "            #add decay for leakiness\n",
    "            #collect spikes over time\n",
    "            #Sprobe = decay * Sprobe + out_state.S\n",
    "        out_rec = torch.stack(out_rec,dim=1)\n",
    "        prediction = torch.max(out_rec,1).values\n",
    "\n",
    "        #prediction = Sprobe\n",
    "        #if i==0:\n",
    "        #    print(prediction)\n",
    "\n",
    "        #accuracy = val_accuracy(prediction,y_train[train_batch_ids[i]])\n",
    "\n",
    "        #class labels only\n",
    "        loss = ce_loss(prediction,y)\n",
    "\n",
    "        print(f'batchloss:  {loss}')\n",
    "\n",
    "        #tonic & torch neuromorphic\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        #model.init_mod_weights(W2)\n",
    "        #sum_acc = sum_acc + accuracy\n",
    "        #sum_loss = sum_loss + loss\n",
    "        avg_loss = ((avg_loss * count) + loss)/(count+1)\n",
    "        count += 1\n",
    "    #avg_train_acc = sum_acc/(len(train_batch_ids))\n",
    "    #avg_loss = sum_loss/(len(train_batch_ids))\n",
    "    #if i == 3:/'\n",
    "    #loss_hist = loss_hist + [float(avg_loss)]\n",
    "    #acc_hist = acc_hist + [float(avg_train_acc)]\n",
    "\n",
    "    toc = time.time()\n",
    "    print(f'time for epoch {epoch}: {toc-tic}')\n",
    "    if epoch%1==0:\n",
    "        print(f'epoch {epoch}: \\n loss: {avg_loss}')\n",
    "        #print(f'train_acc: {avg_train_acc}')\n",
    "    #val_acc,_,_ = validation_acc(X_test,y_test,model,test_batch_ids)\n",
    "    #val_acc_hist = val_acc_hist + [val_acc]\n",
    "    #print(f'val_acc: {val_acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(prediction,y):\n",
    "    return (np.argmax(prediction.detach().numpy(),axis=1) == y.numpy()).sum()/256*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneRecHiddenModel(in_channels=nb_inputs,hidden_channels=nb_hidden,out_channels=nb_outputs,batch_size=batch_size,W=None).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneRecHiddenModel(\n",
       "  (layer1): LifRecPopulation(\n",
       "    (fc_layer): Linear(in_features=700, out_features=200, bias=True)\n",
       "    (rec_layer): Linear(in_features=200, out_features=200, bias=True)\n",
       "  )\n",
       "  (layer2): LifRecPopulation(\n",
       "    (fc_layer): Linear(in_features=200, out_features=20, bias=True)\n",
       "    (rec_layer): Linear(in_features=20, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6200234780f1abd365c930dddb95b38298813a9988d77a8785e770f4fc612d5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
